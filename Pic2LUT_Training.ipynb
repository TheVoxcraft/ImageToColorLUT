{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!cp \"/content/drive/MyDrive/Projects/dataset-scaled.zip\" \"./\"\n",
        "#!unzip -q -u \"./dataset-scaled.zip\" -d \"./dataset/\"\n",
        "!ls -lah ./\n",
        "#!nvidia-sli"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 40G\n",
            "drwxrwxrwx 2 root root    0 May 27 19:37 .\n",
            "drwxrwxrwx 2 root root    0 May 27 19:37 ..\n",
            "-rwxrwxrwx 1 root root  316 May 27 19:38 .amlignore\n",
            "-rwxrwxrwx 1 root root  316 May 27 19:38 .amlignore.amltmp\n",
            "drwxrwxrwx 2 root root    0 May 27 19:38 .ipynb_aml_checkpoints\n",
            "-rwxrwxrwx 1 root root  30K May 31 18:28 Pic2LUT.ipynb\n",
            "-rwxrwxrwx 1 root root 3.3G May 27 19:39 dataset-7500--1.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 31 17:59 dataset-7500--10.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 31 18:04 dataset-7500--12.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 31 18:10 dataset-7500--14.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 31 18:16 dataset-7500--16.npz\n",
            "-rwxrwxrwx 1 root root 286M May 31 18:21 dataset-7500--18.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 27 19:40 dataset-7500--2.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 27 19:49 dataset-7500--3.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 27 20:00 dataset-7500--5.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 27 20:02 dataset-7500--6.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 27 20:13 dataset-7500--7.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 27 20:39 dataset-7500--8.npz\n",
            "-rwxrwxrwx 1 root root 3.3G May 27 22:00 dataset-7500--9.npz\n",
            "-rwxrwxrwx 1 root root  30K May 31 18:28 pic2lut.ipynb.amltmp\n",
            "drwxrwxrwx 2 root root    0 May 27 20:35 trained\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 193236,
          "status": "ok",
          "timestamp": 1621978609165,
          "user": {
            "displayName": "Jonas",
            "photoUrl": "https://lh3.googleusercontent.com/-iWy9MVJzujk/AAAAAAAAAAI/AAAAAAAAq_c/N3DaZN1ln-4/s64/photo.jpg",
            "userId": "11777218575341177824"
          },
          "user_tz": -120
        },
        "id": "5LgYj34Nnoff",
        "outputId": "e5149dbd-a924-4b66-ce4b-c55f1f62e5f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
        "tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')\n",
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "#import pandas as pd\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import gc\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_physical_devices(), tf.test.is_gpu_available(),  tf.test.is_built_with_cuda())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0\n",
            "WARNING:tensorflow:From <ipython-input-2-f37774eff265>:23: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] True True\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1622554440174
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_BASEPATH = \"./dataset-scaled\"\n",
        "\n",
        "\n",
        "#   Create train data\n",
        "# get paths and zip\n",
        "def load_files_from_folder(folderpath, filetype):\n",
        "    all_files = []\n",
        "    for root, dirs, files in os.walk(folderpath):\n",
        "        for file in files:\n",
        "            if file.endswith(filetype):\n",
        "                file_path = os.path.join(root, file)\n",
        "                all_files.append( (file_path, file) )\n",
        "    return all_files\n",
        "\n",
        "luts = load_files_from_folder(DATASET_BASEPATH, \".cube\")\n",
        "luts_db = {}\n",
        "for l in luts:\n",
        "    path, filename = l\n",
        "    luts_db[filename] = path\n",
        "\n",
        "images = load_files_from_folder(DATASET_BASEPATH, \".jpg\")\n",
        "\n",
        "train_paths = []\n",
        "for img in images:\n",
        "    path, filename = img\n",
        "    try:\n",
        "        lut_path = luts_db['lut-'+filename.split('.')[0]+'.cube']\n",
        "        train_paths.append((path, lut_path))\n",
        "    except Exception as e:\n",
        "        print('didnt find lut', e)\n",
        "print(len(train_paths))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1600,
          "status": "ok",
          "timestamp": 1621978610762,
          "user": {
            "displayName": "Jonas",
            "photoUrl": "https://lh3.googleusercontent.com/-iWy9MVJzujk/AAAAAAAAAAI/AAAAAAAAq_c/N3DaZN1ln-4/s64/photo.jpg",
            "userId": "11777218575341177824"
          },
          "user_tz": -120
        },
        "id": "vzzNm60Yt5Ho",
        "outputId": "d96f6693-0c7e-477c-ae44-a79d9b93aee0",
        "gather": {
          "logged": 1622554440297
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LUT TOOLS\n",
        "def get_header(grid_size):\n",
        "    return f\"\"\"\n",
        "#LUT size\n",
        "LUT_3D_SIZE {grid_size}\n",
        "\n",
        "#data domain\n",
        "DOMAIN_MIN 0.0 0.0 0.0\n",
        "DOMAIN_MAX 1.0 1.0 1.0\n",
        "\n",
        "#LUT data points\n",
        "\"\"\"\n",
        "\n",
        "def load_lut_text(path):\n",
        "    with open(path) as fo:\n",
        "        file = fo.readlines()\n",
        "    \n",
        "    file = [i.strip() for i in file]\n",
        "    grid_size = -1\n",
        "    firstlines = file[:64]\n",
        "    for l in firstlines:\n",
        "        if \"LUT_3D_SIZE\" in l:\n",
        "            grid_size = int(l.strip().split(\" \")[1])\n",
        "            break\n",
        "    assert grid_size > 0\n",
        "\n",
        "    firstchars = []\n",
        "    for c in file[:64]:\n",
        "        if len(c) > 0:\n",
        "            firstchars.append(c[0])\n",
        "        else:\n",
        "            firstchars.append(c)\n",
        "    try:\n",
        "        startpoint = min(firstchars.index('0'), firstchars.index('1'))\n",
        "    except ValueError:\n",
        "        startpoint = firstchars.index('0')\n",
        "\n",
        "    return (file[startpoint:], grid_size)\n",
        "\n",
        "def text_to_lut(txt):\n",
        "    assert type(txt) != tuple, \"You might be trying to put in a tuple\"\n",
        "    lut = []\n",
        "    for l in txt:\n",
        "        s = l.strip().split(\" \")\n",
        "        lut.append(tuple([float(i) for i in s]))\n",
        "    return lut\n",
        "\n",
        "def create_lut_file(lut, grid_size):\n",
        "    txt = get_header(grid_size)\n",
        "    for i in lut:\n",
        "        s = f\"{i[0]:.6f} {i[1]:.6f} {i[2]:.6f}\\n\"\n",
        "        txt+=s\n",
        "    return txt\n",
        "\n",
        "def save_to_lut_file(lutstring, outputpath):\n",
        "    with open(outputpath, \"w\") as fo:\n",
        "        fo.write(lutstring)\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1621978610763,
          "user": {
            "displayName": "Jonas",
            "photoUrl": "https://lh3.googleusercontent.com/-iWy9MVJzujk/AAAAAAAAAAI/AAAAAAAAq_c/N3DaZN1ln-4/s64/photo.jpg",
            "userId": "11777218575341177824"
          },
          "user_tz": -120
        },
        "id": "fiJt1ichzVvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del trainX\n",
        "del trainY\n",
        "del validX\n",
        "del validY\n",
        "gc.collect()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "15405"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1621978610763,
          "user": {
            "displayName": "Jonas",
            "photoUrl": "https://lh3.googleusercontent.com/-iWy9MVJzujk/AAAAAAAAAAI/AAAAAAAAq_c/N3DaZN1ln-4/s64/photo.jpg",
            "userId": "11777218575341177824"
          },
          "user_tz": -120
        },
        "id": "QH0yMm4fQ7lG",
        "gather": {
          "logged": 1622502269027
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading images and luts\n",
        "try:\n",
        "    del trainY\n",
        "    del validX\n",
        "    del validY\n",
        "    gc.collect()\n",
        "    time.sleep(0.5)\n",
        "except:\n",
        "    print(\"no trainX to delete\")\n",
        "\n",
        "\n",
        "trainX = []\n",
        "trainY = []\n",
        "from tqdm import tqdm\n",
        "LIMIT_DATASET = 12_000 #\n",
        "bad_shapes = 0\n",
        "random.shuffle(train_paths) # Shuffle training set\n",
        "for paths in tqdm(train_paths[-LIMIT_DATASET:]):\n",
        "   img_path, lut_path = paths\n",
        "   img = tf.keras.preprocessing.image.img_to_array( # not scaled to 0.0-1.0, do in model\n",
        "       tf.keras.preprocessing.image.load_img(img_path)\n",
        "   )\n",
        "\n",
        "   lut = np.array(text_to_lut(\n",
        "       load_lut_text(lut_path)[0]\n",
        "   ))\n",
        "   \n",
        "   if lut.shape == (512,3):\n",
        "       trainX.append(img)\n",
        "       trainY.append(lut)\n",
        "   else:\n",
        "       bad_shapes += 1\n",
        "\n",
        "print(bad_shapes, \"bad shaped luts\")\n",
        "\n",
        "# Create validation data\n",
        "VALIDATION_SPLIT_PERCENTAGE = 0.075\n",
        "valid_split = int(len(trainX)*VALIDATION_SPLIT_PERCENTAGE)\n",
        "\n",
        "# Create numpy arrays\n",
        "validX = np.array(trainX[:valid_split])\n",
        "validY = np.array(trainY[:valid_split])\n",
        "\n",
        "trainX = np.array(trainX[valid_split:])\n",
        "trainY = np.array(trainY[valid_split:])\n",
        "\n",
        "trainX = trainX.reshape(trainX.shape[0], 240, 160, 3)\n",
        "validX = validX.reshape(validX.shape[0], 240, 160, 3)\n",
        "trainY = trainY.reshape(trainY.shape[0], trainY.shape[1] * trainY.shape[2])\n",
        "validY = validY.reshape(validY.shape[0], validY.shape[1] * validY.shape[2])\n",
        "\n",
        "gc.collect()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 3/11000 [00:00<06:54, 26.55it/s]no trainX to delete\n",
            "100%|██████████| 11000/11000 [09:25<00:00, 19.45it/s]\n",
            "233 bad shaped luts\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "49"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 56484,
          "status": "ok",
          "timestamp": 1621978667244,
          "user": {
            "displayName": "Jonas",
            "photoUrl": "https://lh3.googleusercontent.com/-iWy9MVJzujk/AAAAAAAAAAI/AAAAAAAAq_c/N3DaZN1ln-4/s64/photo.jpg",
            "userId": "11777218575341177824"
          },
          "user_tz": -120
        },
        "id": "l7prVyZ2ysqF",
        "outputId": "5f334f2f-2f2b-4121-b954-533e46bbf604",
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load from training data cache\n",
        "BASE_PATH_CACHE = \"./\"\n",
        "\n",
        "firsttime_bool = True\n",
        "for files in load_files_from_folder(BASE_PATH_CACHE, \".npz\"):\n",
        "    path = files[0]\n",
        "    print(\"Loading:\", path)\n",
        "    arrays = np.load(path)\n",
        "    if firsttime_bool:\n",
        "        trainX = arrays['arr_0'].astype('uint8')\n",
        "        trainY = arrays['arr_1'].astype('float16')\n",
        "        validX = arrays['arr_2'].astype('uint8')\n",
        "        validY = arrays['arr_3'].astype('float16')\n",
        "        firsttime_bool = False\n",
        "    else:\n",
        "        trainX = np.concatenate((arrays['arr_0'].astype('uint8'), trainX))\n",
        "        trainY = np.concatenate((arrays['arr_1'].astype('float16'), trainY))\n",
        "        validX = np.concatenate((arrays['arr_2'].astype('uint8'), validX))\n",
        "        validY = np.concatenate((arrays['arr_3'].astype('float16'), validY))\n",
        "        break\n",
        "    del arrays\n",
        "    gc.collect()\n",
        "    print(trainX.shape, (sys.getsizeof(trainX)+sys.getsizeof(trainY))//1000000, \"mb\")\n",
        "\n",
        "print(trainX.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: ./dataset-7500--1.npz\n",
            "(6754, 240, 160, 3) 798 mb\n",
            "Loading: ./dataset-7500--10.npz\n",
            "(13521, 240, 160, 3)\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1622554701339
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check = [(i.shape, i.dtype) for i in trainX]\n",
        "for i in check:\n",
        "    if i != check[0]:\n",
        "        print(\"ERROR X\")\n",
        "check = [(i.shape, i.dtype) for i in trainY]\n",
        "for i in check:\n",
        "    if i != check[0]:\n",
        "        print(\"ERROR Y\")\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainX' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ac3ad95e583b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ERROR X\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainX' is not defined"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 184,
          "status": "ok",
          "timestamp": 1621978667643,
          "user": {
            "displayName": "Jonas",
            "photoUrl": "https://lh3.googleusercontent.com/-iWy9MVJzujk/AAAAAAAAAAI/AAAAAAAAq_c/N3DaZN1ln-4/s64/photo.jpg",
            "userId": "11777218575341177824"
          },
          "user_tz": -120
        },
        "id": "ZRd299XE_drN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "gc.collect()\n",
        "print(\"Size of training data:\",(sys.getsizeof(trainX)+sys.getsizeof(trainY))//1000000,\"mb\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training data: 12859 mb\n"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1621978667643,
          "user": {
            "displayName": "Jonas",
            "photoUrl": "https://lh3.googleusercontent.com/-iWy9MVJzujk/AAAAAAAAAAI/AAAAAAAAq_c/N3DaZN1ln-4/s64/photo.jpg",
            "userId": "11777218575341177824"
          },
          "user_tz": -120
        },
        "id": "g7uPWjKG5RHR",
        "outputId": "7b9e2d4b-f9d3-4854-be51-134d577ed00e",
        "gather": {
          "logged": 1622537406150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX.shape, trainY.shape)\n",
        "print(validX.shape, validY.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13521, 240, 160, 3) (13521, 1536)\n",
            "(1175, 240, 160, 3) (1175, 1536)\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1621978667644,
          "user": {
            "displayName": "Jonas",
            "photoUrl": "https://lh3.googleusercontent.com/-iWy9MVJzujk/AAAAAAAAAAI/AAAAAAAAq_c/N3DaZN1ln-4/s64/photo.jpg",
            "userId": "11777218575341177824"
          },
          "user_tz": -120
        },
        "id": "MSiJoi0lDCPF",
        "outputId": "fae11bdf-f88b-4f67-cacb-6b1391eef323",
        "gather": {
          "logged": 1622554704334
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating model\n",
        "initializer = tf.random_normal_initializer(0., 0.02)\n",
        "model = keras.Sequential()\n",
        "model.add(layers.experimental.preprocessing.Rescaling(1.0 / 255, input_shape=(240,160,3)))\n",
        "model.add(layers.Conv2D(filters=72, kernel_size=(3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(layers.Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(units=1536,activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.45))\n",
        "model.add(layers.Dense(units=1536,activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(units=1536,activation=\"linear\"))\n",
        "'''\n",
        "model.add(layers.experimental.preprocessing.Rescaling(1.0 / 255, input_shape=(240,160,3)))\n",
        "#model.add(layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "#model.add(layers.BatchNormalization())\n",
        "#model.add(layers.Conv2D(filters=24, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "#model.add(layers.Conv2D(filters=4, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer='he_uniform'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "#model.add(layers.BatchNormalization())\n",
        "#model.add(layers.Conv2DTranspose(48, 4, strides=2,\n",
        "#                                    padding='same',\n",
        "#                                    kernel_initializer=initializer))\n",
        "#model.add(layers.Conv2D(filters=48, kernel_size=(3,3), padding=\"same\", activation='relu', kernel_initializer='he_uniform'))\n",
        "#model.add(layers.BatchNormalization())\n",
        "#model.add(layers.Conv2D(filters=3, kernel_size=(2,2), padding=\"same\", activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(layers.Flatten())\n",
        "#model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Dense(units=1024, activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(units=768, activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(units=1536, activation=\"linear\"))\n",
        "'''\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling_4 (Rescaling)      (None, 240, 160, 3)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 120, 80, 3)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 60, 40, 3)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 30, 20, 3)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1800)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1024)              1844224   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 768)               787200    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1536)              1181184   \n",
            "=================================================================\n",
            "Total params: 3,812,608\n",
            "Trainable params: 3,812,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1484,
          "status": "ok",
          "timestamp": 1621978669124,
          "user": {
            "displayName": "Jonas",
            "photoUrl": "https://lh3.googleusercontent.com/-iWy9MVJzujk/AAAAAAAAAAI/AAAAAAAAq_c/N3DaZN1ln-4/s64/photo.jpg",
            "userId": "11777218575341177824"
          },
          "user_tz": -120
        },
        "id": "k1EKyzDg6wpZ",
        "outputId": "99000a88-8599-48f8-a565-4892816c16c8",
        "gather": {
          "logged": 1622554840640
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = f\"simple-model-{int(time.time())}\"\n",
        "filename = NAME+\"_model-{epoch:02d}-{val_accuracy:.3f}\"\n",
        "models_folder = \"./trained/models/\"\n",
        "logs_folder = \"./trained/logs\"\n",
        "\n",
        "\n",
        "# Load model\n",
        "#model = None\n",
        "#model = tf.keras.models.load_model('./trained/models/large2-model-1622493336_model-32-0.081.model')\n",
        "\n",
        "opt = tf.keras.optimizers.Adam() # learning_rate=0.0005, decay=1e-6\n",
        "model.compile(optimizer=opt, loss=\"mse\", metrics=\"accuracy\") \n",
        "checkpoint = ModelCheckpoint(models_folder+\"{}.model\".format(filename, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'), verbose=0,period=8) # saves only the best ones\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=logs_folder+\"/{}\".format(NAME), profile_batch=0)\n",
        "\n",
        "print(trainX.shape, trainY.shape)\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 100\n",
        "print(\"Training: \"+NAME) \n",
        "history = model.fit(x=trainX, y=trainY, batch_size=BATCH_SIZE, validation_data=(validX, validY), epochs=EPOCHS, callbacks=[tensorboard, checkpoint]) # Train\n",
        "\n",
        "model.save(f\"{models_folder}latest-{NAME}-e{EPOCHS}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "(13521, 240, 160, 3) (13521, 1536)\n",
            "Training: simple-model-1622554860\n",
            "Epoch 1/20\n",
            "136/136 [==============================] - 2s 14ms/step - loss: 0.0464 - accuracy: 0.0090 - val_loss: 0.0261 - val_accuracy: 0.0136\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 2/20\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 0.0209 - accuracy: 0.0190 - val_loss: 0.0184 - val_accuracy: 0.0706\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 3/20\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 0.0199 - accuracy: 0.0207 - val_loss: 0.0182 - val_accuracy: 0.0672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 4/20\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 0.0197 - accuracy: 0.0209 - val_loss: 0.0183 - val_accuracy: 0.0213\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 5/20\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 0.0197 - accuracy: 0.0202 - val_loss: 0.0184 - val_accuracy: 0.0681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 6/20\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 0.0197 - accuracy: 0.0214 - val_loss: 0.0183 - val_accuracy: 0.0630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 7/20\n",
            "136/136 [==============================] - 1s 9ms/step - loss: 0.0195 - accuracy: 0.0222 - val_loss: 0.0182 - val_accuracy: 0.0689\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 8/20\n",
            "132/136 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.0217WARNING:tensorflow:From /anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: ./trained/models/simple-model-1622554860_model-08-0.037.model/assets\n",
            "136/136 [==============================] - 5s 35ms/step - loss: 0.0195 - accuracy: 0.0219 - val_loss: 0.0188 - val_accuracy: 0.0374\n",
            "Epoch 9/20\n",
            "136/136 [==============================] - 1s 10ms/step - loss: 0.0195 - accuracy: 0.0233 - val_loss: 0.0183 - val_accuracy: 0.0681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "Epoch 10/20\n",
            " 37/136 [=======>......................] - ETA: 0s - loss: 0.0197 - accuracy: 0.0249\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 43/136 [========>.....................] - ETA: 0s - loss: 0.0197 - accuracy: 0.0247"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BWHu8Zk94nd",
        "tags": [],
        "gather": {
          "logged": 1622553462143
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(validX, validY, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.01597711257636547\n",
            "Test accuracy: 0.08163265138864517\n"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P3y1ujsMQps5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 3,
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}